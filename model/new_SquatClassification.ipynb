{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"18B90Ay0ySIrP7P9jOtjrNu68JevTQthK","timestamp":1677684036817}],"collapsed_sections":["1pFvIexjWzxC","7QvBpL85413Z","sp1BN44HBYMe","caK6A26I48kw"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","metadata":{"id":"2fXF_T3bSEa_"},"source":["## Colab Setup"]},{"cell_type":"code","metadata":{"id":"EqEDSdeoOXpn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677915835528,"user_tz":-540,"elapsed":30239,"user":{"displayName":"궈노민","userId":"17233137132235511457"}},"outputId":"7726c915-091c-4ed5-9d2b-3071a37b7014"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["\"\"\"\n","민동전용 cd\n","\"\"\"\n","%cd /content/drive/MyDrive/MLVU/project"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TnJ9WQQwrz6q","executionInfo":{"status":"ok","timestamp":1677830770459,"user_tz":-540,"elapsed":1,"user":{"displayName":"권권오오민","userId":"09300716277592230366"}},"outputId":"8d195040-1e43-468c-e273-4b112eee81a6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[Errno 2] No such file or directory: '/content/drive/MyDrive/MLVU/project'\n","/content/drive/MyDrive/Colab Notebooks\n"]}]},{"cell_type":"code","metadata":{"id":"c57lCStiOyqA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677915840724,"user_tz":-540,"elapsed":2,"user":{"displayName":"궈노민","userId":"17233137132235511457"}},"outputId":"ba31d2d4-196b-4b4c-911b-89ee1d46950c"},"source":["\"\"\"\n","Change directory to where this file is located\n","\"\"\"\n","%cd /content/drive/MyDrive/Colab Notebooks"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks\n"]}]},{"cell_type":"code","source":["tf.test.gpu_device_name()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"F5ExeIswdkxu","executionInfo":{"status":"ok","timestamp":1677893377847,"user_tz":-540,"elapsed":4206,"user":{"displayName":"­권오민 / 학생 / 전기·정보공학부","userId":"14836171550716712824"}},"outputId":"01301d81-1e84-42b1-8d2c-77869f00dff2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/device:GPU:0'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["## Import Modules:\n","\n"],"metadata":{"id":"dHY1BNH4PcQt"}},{"cell_type":"code","source":["import tensorflow as tf\n","import json\n","from tensorflow.keras.layers import Conv1D,Input,ZeroPadding2D,BatchNormalization,AveragePooling2D, Conv2D,Dropout,Normalization,Softmax\n","from tqdm import tqdm\n","import numpy as np\n","import os\n","from scipy import special\n","from sklearn.utils import shuffle\n","from sklearn import preprocessing\n","from tensorflow.keras import regularizers\n","from matplotlib import pyplot as plt"],"metadata":{"id":"71pC0E6Rh_Us","executionInfo":{"status":"ok","timestamp":1677915849343,"user_tz":-540,"elapsed":5688,"user":{"displayName":"궈노민","userId":"17233137132235511457"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["ftrain_x=\"nobbr_train_x\" \n","fvalid_x=\"nobbr_valid_x\"\n","ftest_x=\"nobbr_test_x\"\n","ftrain_labels =\"nobbr_train_labels\"\n","fvalid_labels =\"nobbr_valid_labels\"\n","ftest_labels=\"nobbr_test_labels\"\n","data_path = './Pose_Dataset/'\n","\n","channel=256\n","\n","checkpoint_path = \"ck1/cp.ckpt\"  #reference model weight이 저장되어 있음.\n","checkpoint_path2=\"ck2/cp.ckpt\"   #reference model learning rate 다르게 하면서 update 하는 용도\n","checkpoint_path3=\"ck3/cp.ckpt\"  #dense model weight이 저장되어 있음.\n","checkpoint_path4=\"ck4/cp.ckpt\"  #dense model learning rate 다르게 하면서 update 하는 용도\n","checkpoint_dir = os.path.dirname(checkpoint_path)"],"metadata":{"id":"hFD5j2u2IMHn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#At First Loading"],"metadata":{"id":"EEwiq-AZH_1u"}},{"cell_type":"markdown","source":["## Data Load\n","\n"],"metadata":{"id":"PUJN9gg__eYm"}},{"cell_type":"code","source":["!apt install unzip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_nAI60vH06QC","executionInfo":{"status":"ok","timestamp":1677893403235,"user_tz":-540,"elapsed":2328,"user":{"displayName":"­권오민 / 학생 / 전기·정보공학부","userId":"14836171550716712824"}},"outputId":"fc2630c3-b695-49b6-ad4f-4560db041653"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","unzip is already the newest version (6.0-25ubuntu1.1).\n","0 upgraded, 0 newly installed, 0 to remove and 22 not upgraded.\n"]}]},{"cell_type":"code","source":["!ls \"/content/drive/My Drive/Colab Notebooks/\""],"metadata":{"id":"OCRIpGCM1Eal"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!unzip -q \"/content/drive/My Drive/Colab Notebooks/Pose_Dataset.zip\"\n"],"metadata":{"id":"zzi7xeIS0L3G","executionInfo":{"status":"ok","timestamp":1677893521882,"user_tz":-540,"elapsed":117072,"user":{"displayName":"­권오민 / 학생 / 전기·정보공학부","userId":"14836171550716712824"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"03bff01b-4a07-40e8-afde-c68dc2556fb2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["replace __MACOSX/._Pose_Dataset? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"]}]},{"cell_type":"code","source":["import json\n","\n","\n","labels=['bad_back_round','bad_back_warp','bad_head','bad_innner_thigh','bad_shallow','bad_toe','good']\n","paths={'bad_back_round':0,\n","       'bad_back_warp':0,\n","       'bad_head':0,\n","       'bad_innner_thigh':0,\n","       'bad_shallow':0,\n","       'bad_toe':0,\n","       'good':0}\n","\n","for label in labels:\n","    paths[label]=data_path+label+\"/1115_3djoints_index\"\n","\n","\n","json_files={'bad_back_round':0,\n","       'bad_back_warp':0,\n","       'bad_head':0,\n","       'bad_innner_thigh':0,\n","       'bad_shallow':0,\n","       'bad_toe':0,\n","       'good':0}\n","\n","\n","for label in labels:\n","    json_files[label]=[pos_json for pos_json in os.listdir(paths[label]) if pos_json.endswith('.json')]\n","\n","data={'bad_back_round':[],'bad_back_warp':[],'bad_head':[],'bad_innner_thigh':[],'bad_shallow':[],'bad_toe':[],'good':[]}\n","\n","for label in tqdm(labels):\n","    for single_file in json_files[label]:\n","        file_path=paths[label]+\"/\"+single_file\n","        with open(file_path,'r') as fp:\n","            data[label].append(json.load(fp))"],"metadata":{"id":"m9EfzcObkbjq","colab":{"base_uri":"https://localhost:8080/"},"outputId":"be253f18-3891-42b6-f277-9f2e4f85d236","executionInfo":{"status":"ok","timestamp":1677893582516,"user_tz":-540,"elapsed":58764,"user":{"displayName":"­권오민 / 학생 / 전기·정보공학부","userId":"14836171550716712824"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 7/7 [00:57<00:00,  8.28s/it]\n"]}]},{"cell_type":"code","source":["data_numpy={}\n","entire_num=0\n","for label in labels:\n","    label_list=[]\n","    for i in tqdm(range(len(data[label]))):\n","        my_list=[]\n","        for j in range(300):\n","            my_list.append(data[label][i][str(j)]['3d_joint']) \n","        label_list.append(my_list)\n","    label_numpy=np.array(label_list)\n","    data_numpy[label]=label_numpy\n","    entire_num+=data_numpy[label].shape[0]\n","    print(data_numpy[label].shape)\n","print(entire_num)"],"metadata":{"id":"9bhjqVcxMyv5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677893596685,"user_tz":-540,"elapsed":10191,"user":{"displayName":"­권오민 / 학생 / 전기·정보공학부","userId":"14836171550716712824"}},"outputId":"df06c936-2fcf-4ba8-d3bc-3d4a9289968f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 280/280 [00:00<00:00, 5400.76it/s]\n"]},{"output_type":"stream","name":"stdout","text":["(280, 300, 171)\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 312/312 [00:00<00:00, 2911.53it/s]\n"]},{"output_type":"stream","name":"stdout","text":["(312, 300, 171)\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 272/272 [00:00<00:00, 2459.88it/s]\n"]},{"output_type":"stream","name":"stdout","text":["(272, 300, 171)\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 230/230 [00:00<00:00, 2710.66it/s]\n"]},{"output_type":"stream","name":"stdout","text":["(230, 300, 171)\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 319/319 [00:00<00:00, 3267.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["(319, 300, 171)\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 295/295 [00:00<00:00, 7268.94it/s]\n"]},{"output_type":"stream","name":"stdout","text":["(295, 300, 171)\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 293/293 [00:00<00:00, 7715.49it/s]\n"]},{"output_type":"stream","name":"stdout","text":["(293, 300, 171)\n","2001\n"]}]},{"cell_type":"markdown","source":["## Data Augmentation"],"metadata":{"id":"1pFvIexjWzxC"}},{"cell_type":"code","source":["#300 프레임 중 연속된 200프레임,150프레임, 100프레임을 무작위로 추출하여 300프레임으로 늘려줘서 데이터셋에 추가시켜준다.\n","#이는 다양한 속도의 스쿼트를 학습 시키는데 도움을 준다.\n","\n","import random\n","data_200={}\n","data_150={}\n","data_100={}\n","test_samples={}\n","test_labels=[]\n","\n","test=0\n","train=0\n","addition=0\n","for label in labels[1:]:\n","  #test셋은 augmentation data를 포함하지 않은 원본에서 10퍼센트를 뽑아준다. \n","  np.random.shuffle(data_numpy[label])\n","  print(\"합계\",data_numpy[label].shape[0])\n","  num_test=int(0.1*len(data_numpy[label]))\n","  test_samples[label]=data_numpy[label][0:num_test,:,:]\n","  data_numpy[label]=data_numpy[label][num_test:,:,:]\n","  size=len(data_numpy[label])\n","  print(test_samples[label].shape[0],data_numpy[label].shape[0])\n","  test+=test_samples[label].shape[0]\n","  train+=data_numpy[label].shape[0]\n","   \n","  #150 frames augmentation\n","  a=np.arange(300)\n","  xp1=np.arange(0,300,2)\n","  data_150[label]=np.zeros((int(size/3),300,171))\n","  for i in range(int(size/3)):\n","    seed_150=random.randint(0,150)\n","    for j in range(171):\n","      fp=data_numpy[label][i,seed_150:seed_150+150,j]\n","      data_150[label][i,:,j]=np.interp(a,xp1,fp)\n","  addition+=data_150[label].shape[0]\n","\n","\n","  #200 frames augmentation\n","  xp3=np.arange(0,600,3)  \n","  np.random.shuffle(data_numpy[label])\n","  candidate=np.zeros((int(size/3),600,171))\n","  data_200[label]=np.zeros((int(size/3),300,171))\n","  b=np.arange(600)\n","  for i in range(int(size/3)):\n","    seed_200=random.randint(0,100)\n","    for j in range(171):\n","        fp=data_numpy[label][i,seed_200:seed_200+200,j]\n","        candidate[i,:,j]=np.interp(b,xp3,fp)\n","        data_200[label][i,:,j]=candidate[i,::2,j]\n","  addition+=data_200[label].shape[0]\n","  \n","  #100 frames augmentation\n","  np.random.shuffle(data_numpy[label])\n","  xp2=np.arange(0,300,3)\n","  data_100[label]=np.zeros((int(size/3),300,171))\n","  for i in range(int(size/3)):\n","    seed_100=random.randint(0,200)\n","    for j in range(171):\n","      fp=data_numpy[label][i,seed_100:seed_100+100,j]\n","      data_100[label][i,:,j]=np.interp(a,xp2,fp)\n","  addition+=data_100[label].shape[0]\n","      \n","print(\"test\",test,\"train\",train,\"addtion\",addition,\"entrie_num\",entire_num)"],"metadata":{"id":"kSUhZqR1WzVS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677893609401,"user_tz":-540,"elapsed":4327,"user":{"displayName":"­권오민 / 학생 / 전기·정보공학부","userId":"14836171550716712824"}},"outputId":"e9437b02-f632-4b50-a12a-8c3ef910a2d6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["합계 312\n","31 281\n","합계 272\n","27 245\n","합계 230\n","23 207\n","합계 319\n","31 288\n","합계 295\n","29 266\n","합계 293\n","29 264\n","test 170 train 1551 addtion 1545 entrie_num 2001\n"]}]},{"cell_type":"markdown","source":["##Data Preprocessing"],"metadata":{"id":"ut-0Y_Ve2PQ3"}},{"cell_type":"markdown","source":["###Split the Dataset"],"metadata":{"id":"Z-9L7j5w2ZyY"}},{"cell_type":"markdown","source":["#### 모두 포함"],"metadata":{"id":"lpsLM6IQKuYi"}},{"cell_type":"code","source":["train_samples={}\n","valid_samples={}\n","labels=['bad_back_round','bad_back_warp','bad_head','bad_innner_thigh','bad_shallow','bad_toe','good']\n","label_encoding={'bad_back_round':[1,0,0,0,0,0,0],'bad_back_warp':[0,1,0,0,0,0,0],'bad_head':[0,0,1,0,0,0,0],'bad_innner_thigh':[0,0,0,1,0,0,0],'bad_shallow':[0,0,0,0,1,0,0],'bad_toe':[0,0,0,0,0,1,0],'good':[0,0,0,0,0,0,1]}\n","train_labels=[]\n","valid_labels=[]\n","train_x=[]\n","valid_x=[]\n","test_x=[]\n","number_data=0\n","\n","\n","\n","\n","#train: valid= 8:2로 나눠봄\n","for label in labels:\n","    np.random.shuffle(data_numpy[label])\n","    np.random.shuffle(data_150[label])\n","    np.random.shuffle(data_100[label])\n","    number_data+=len(data_numpy[label])+len(data_150[label])+len(data_100[label])+len(data_200[label])\n","    entire_sample=np.concatenate((data_numpy[label],data_150[label],data_100[label],data_200[label]),axis=0)\n","    num_train=int(0.8*len(entire_sample))\n","    train_samples[label],valid_samples[label]=entire_sample[:num_train,:,:],entire_sample[num_train:,:,:]\n","\n","\n","\n","for label in labels:\n","    #print(\"----\"+label+\"-----\")\n","    for i in range(train_samples[label].shape[0]): \n","        train_labels.append(label_encoding[label])\n","        train_x.append(train_samples[label][i,:,:].transpose())\n","    \n","    for i in range(valid_samples[label].shape[0]):\n","        valid_labels.append(label_encoding[label])\n","        valid_x.append(valid_samples[label][i,:,:].transpose())\n","    \n","    for i in range(test_samples[label].shape[0]):\n","        test_labels.append(label_encoding[label])   \n","        test_x.append(test_samples[label][i,:,:].transpose()) \n","\n","train_x=np.array(train_x)\n","train_labels=np.array(train_labels)\n","\n","valid_x=np.array(valid_x)\n","valid_labels=np.array(valid_labels)\n","test_x=np.array(test_x)\n","test_labels=np.array(test_labels)\n","\n","\n","\n","train_x,train_labels=shuffle(train_x,train_labels)\n","valid_x,valid_labels=shuffle(valid_x,valid_labels)\n","test_x,test_labels=shuffle(test_x,test_labels)\n","\n","train_labels = train_labels.reshape(-1, 1, 1, 7)\n","valid_labels = valid_labels.reshape(-1, 1, 1, 7)\n","test_labels=test_labels.reshape((-1,1,1,7))\n","\n","print(\"train_x\",train_x.shape)\n","print(\"train_label\",train_labels.shape)\n","\n","print(\"test_x\",test_x.shape)\n","print(\"test_label\",test_labels.shape)\n","\n","print(\"valid_x\",valid_x.shape)\n","print(\"valid_label\",valid_labels.shape)\n","\n","print(\"num_data\",number_data)\n"],"metadata":{"id":"Nf8xrDHVUcpv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["a=np.random.randint(1,6)\n","print(a)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Czj0L6TojuT7","executionInfo":{"status":"ok","timestamp":1677898789851,"user_tz":-540,"elapsed":4,"user":{"displayName":"­권오민 / 학생 / 전기·정보공학부","userId":"14836171550716712824"}},"outputId":"5cf013fc-f063-400f-d6d8-95f70728b9d0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2\n"]}]},{"cell_type":"markdown","source":["#### Bad Back round 제외"],"metadata":{"id":"XFHnTaFzJd_R"}},{"cell_type":"code","source":["nobbr_train_labels=[]\n","nobbr_test_labels=[]\n","nobbr_valid_labels=[]\n","nobbr_train_x=[]\n","nobbr_valid_x=[]\n","nobbr_test_x=[]\n","for i,label in enumerate(train_labels):\n","    if(label[0][0][0]==1):\n","        pass\n","    elif(label[0][0][1]==1):\n","        a=np.random.randint(1,6)\n","        if(a==1):\n","            nobbr_train_x.append(train_x[i])\n","            nobbr_train_labels.append(label)\n","    elif(label[0][0][2]==1):\n","        a=np.random.randint(1,6)\n","        if(a==1):\n","            nobbr_train_x.append(train_x[i])\n","            nobbr_train_labels.append(label)\n","    elif(label[0][0][3]==1):\n","        a=np.random.randint(1,6)\n","        if(a==1):\n","            nobbr_train_x.append(train_x[i])\n","            nobbr_train_labels.append(label)\n","    elif(label[0][0][4]==1):\n","        a=np.random.randint(1,6)\n","        if(a==1):\n","            nobbr_train_x.append(train_x[i])\n","            nobbr_train_labels.append(label)\n","    elif(label[0][0][5]==1):\n","        a=np.random.randint(1,6)\n","        if(a==1):\n","            nobbr_train_x.append(train_x[i])\n","            nobbr_train_labels.append(label)\n","    else:\n","        nobbr_train_x.append(train_x[i])\n","        nobbr_train_labels.append(label)\n","for i,label in enumerate(valid_labels):\n","    if(label[0][0][0]==1):\n","        pass\n","    elif(label[0][0][1]==1):\n","        a=np.random.randint(1,6)\n","        if(a==1):\n","            nobbr_valid_x.append(valid_x[i])\n","            nobbr_valid_labels.append(label)\n","    elif(label[0][0][2]==1):\n","        a=np.random.randint(1,6)\n","        if(a==1):\n","            nobbr_valid_x.append(valid_x[i])\n","            nobbr_valid_labels.append(label)\n","    elif(label[0][0][3]==1):\n","        a=np.random.randint(1,6)\n","        if(a==1):\n","            nobbr_valid_x.append(valid_x[i])\n","            nobbr_valid_labels.append(label)\n","    elif(label[0][0][4]==1):\n","        a=np.random.randint(1,6)\n","        if(a==1):\n","            nobbr_valid_x.append(valid_x[i])\n","            nobbr_valid_labels.append(label)\n","    elif(label[0][0][5]==1):\n","        a=np.random.randint(1,6)\n","        if(a==1):\n","            nobbr_valid_x.append(valid_x[i])\n","            nobbr_valid_labels.append(label)\n","    else:\n","        nobbr_valid_x.append(valid_x[i])\n","        nobbr_valid_labels.append(label)\n","for i,label in enumerate(test_labels):\n","    if(label[0][0][0]==1):\n","        pass\n","    elif(label[0][0][1]==1):\n","        a=np.random.randint(1,6)\n","        if(a==1):\n","            nobbr_test_x.append(test_x[i])\n","            nobbr_test_labels.append(label)\n","    elif(label[0][0][2]==1):\n","        a=np.random.randint(1,6)\n","        if(a==1):\n","            nobbr_test_x.append(test_x[i])\n","            nobbr_test_labels.append(label)\n","    elif(label[0][0][3]==1):\n","        a=np.random.randint(1,6)\n","        if(a==1):\n","            nobbr_test_x.append(test_x[i])\n","            nobbr_test_labels.append(label)\n","    elif(label[0][0][4]==1):\n","        a=np.random.randint(1,6)\n","        if(a==1):\n","            nobbr_test_x.append(test_x[i])\n","            nobbr_test_labels.append(label)\n","    elif(label[0][0][5]==1):\n","        a=np.random.randint(1,6)\n","        if(a==1):\n","            nobbr_test_x.append(test_x[i])\n","            nobbr_test_labels.append(label)\n","    else:\n","        nobbr_test_x.append(test_x[i])\n","        nobbr_test_labels.append(label)"],"metadata":{"id":"mKqxHCNpYklC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nobbr_train_x=np.array(nobbr_train_x)\n","nobbr_valid_x=np.array(nobbr_valid_x)\n","nobbr_test_x=np.array(nobbr_test_x)\n","nobbr_train_labels=np.array(nobbr_train_labels)\n","nobbr_test_labels=np.array(nobbr_test_labels)\n","nobbr_valid_labels=np.array(nobbr_valid_labels)"],"metadata":{"id":"8oX04cwOdp1G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(nobbr_train_x.shape,nobbr_train_labels.shape)\n","print(nobbr_test_x.shape,nobbr_test_labels.shape)\n","print(nobbr_valid_x.shape,nobbr_valid_labels.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cLUYfrmYd9IH","executionInfo":{"status":"ok","timestamp":1677899183972,"user_tz":-540,"elapsed":342,"user":{"displayName":"­권오민 / 학생 / 전기·정보공학부","userId":"14836171550716712824"}},"outputId":"b624cca4-9da2-47d2-d682-e6770023af24"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(813, 171, 300) (813, 1, 1, 7)\n","(51, 171, 300) (51, 1, 1, 7)\n","(208, 171, 300) (208, 1, 1, 7)\n"]}]},{"cell_type":"markdown","source":["#### Good label"],"metadata":{"id":"Crt7mmekJipx"}},{"cell_type":"code","source":["train_good_labels=[]\n","valid_good_labels=[]\n","np.random.shuffle(data_numpy['good'])\n","np.random.shuffle(data_150['good'])\n","np.random.shuffle(data_100['good'])\n","number_good=len(data_numpy['good'])+len(data_150['good'])+len(data_100['good'])+len(data_200['good'])\n","good_samples=np.concatenate((data_numpy['good'],data_150['good'],data_100['good'],data_200['good']),axis=0)\n","num_train=int(0.8*len(good_samples))\n","train_good,valid_good=good_samples[:num_train,:,:],good_samples[num_train:,:,:]\n","\n","\n","\n","for i in range(train_good.shape[0]): \n","    train_good_labels.append(label_encoding['good'])\n","for i in range(valid_good.shape[0]):\n","    valid_good_labels.append(label_encoding['good'])\n","\n","train_good=np.array(train_good)\n","train_good_labels=np.array(train_good_labels)\n","valid_good=np.array(valid_good)\n","valid_good_labels=np.array(valid_good_labels)\n","\n","\n","train_good,train_good_labels=shuffle(train_good,train_good_labels)\n","valid_good,valid_good_labels=shuffle(valid_good,valid_good_labels)\n","train_good_labels = train_good_labels.reshape(-1, 1, 1, 7)\n","valid_good_labels=valid_good_labels.reshape(-1,1,1,7)\n","\n","\n","print(train_good.shape,valid_good.shape,train_good_labels.shape,valid_good_labels.shape)\n","\n"],"metadata":{"id":"Y-LTSXACicLD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677893652953,"user_tz":-540,"elapsed":871,"user":{"displayName":"­권오민 / 학생 / 전기·정보공학부","userId":"14836171550716712824"}},"outputId":"7bf7c180-335d-4993-83f6-7ea921cd36ab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(422, 300, 171) (106, 300, 171) (422, 1, 1, 7) (106, 1, 1, 7)\n"]}]},{"cell_type":"code","source":["train_good=train_good.reshape((-1,171,300))\n","valid_good=valid_good.reshape((-1,171,300))\n","print(train_good.shape)\n","print(valid_good.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9T3lQxPz4TPU","executionInfo":{"status":"ok","timestamp":1677856783062,"user_tz":-540,"elapsed":846,"user":{"displayName":"권오민","userId":"11126259349669748161"}},"outputId":"d52d6bce-fba5-4b0e-bebb-1aa0df0a459f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(422, 171, 300)\n","(106, 171, 300)\n"]}]},{"cell_type":"markdown","source":["###Normalization"],"metadata":{"id":"4nPn5nFOXirO"}},{"cell_type":"code","source":["from sklearn.preprocessing import MinMaxScaler\n","\n","\n","\n","for i in range(len(nobbr_train_x)):\n","  scaler = MinMaxScaler()\n","  matrix=nobbr_train_x[i]\n","  matrix_one_column=matrix.reshape((-1,1))\n","  scaler.fit(matrix_one_column)\n","  normalized_arr = scaler.transform(matrix_one_column)\n","  nobbr_train_x[i]=normalized_arr.reshape((matrix.shape))\n","\n","for i in range(len(nobbr_valid_x)):\n","  scaler = MinMaxScaler()\n","  matrix=nobbr_valid_x[i]\n","  matrix_one_column=matrix.reshape((-1,1))\n","  scaler.fit(matrix_one_column)\n","  normalized_arr = scaler.transform(matrix_one_column)\n","  nobbr_valid_x[i]=normalized_arr.reshape((matrix.shape))\n","\n","for i in range(len(nobbr_test_x)):\n","  scaler = MinMaxScaler()\n","  matrix=nobbr_test_x[i]\n","  matrix_one_column=matrix.reshape((-1,1))\n","  scaler.fit(matrix_one_column)\n","  normalized_arr = scaler.transform(matrix_one_column)\n","  nobbr_test_x[i]=normalized_arr.reshape((matrix.shape))\n"],"metadata":{"id":"tQ_FuxPTXhLK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(len(train_good)):\n","  scaler = MinMaxScaler()\n","  matrix=train_good[i]\n","  matrix_one_column=matrix.reshape((-1,1))\n","  scaler.fit(matrix_one_column)\n","  normalized_arr = scaler.transform(matrix_one_column)\n","  train_good[i]=normalized_arr.reshape((matrix.shape))\n","\n","for i in range(len(valid_good)):\n","  scaler = MinMaxScaler()\n","  matrix=valid_good[i]\n","  matrix_one_column=matrix.reshape((-1,1))\n","  scaler.fit(matrix_one_column)\n","  normalized_arr = scaler.transform(matrix_one_column)\n","  valid_good[i]=normalized_arr.reshape((matrix.shape))\n"],"metadata":{"id":"73mZPWD64tdv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Delete unneccessary files"],"metadata":{"id":"ucJvjW4B2iVk"}},{"cell_type":"code","source":["del train_samples\n","del valid_samples\n","del test_samples\n","del data_100\n","del data_150\n","del data_200 \n","del data_numpy"],"metadata":{"id":"ej3jh7Oihb6E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["del data"],"metadata":{"id":"dWMD6C_PzCWq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["del paths\n","del json_files"],"metadata":{"id":"R7xVUOPxzJ_v"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### test,train,valid 저장"],"metadata":{"id":"0U1-crzrEmYK"}},{"cell_type":"code","source":["np.save(ftrain_x,train_x)\n","np.save(ftest_x,test_x)\n","np.save(fvalid_x,valid_x)\n","np.save(ftrain_labels,train_labels)\n","np.save(ftest_labels,test_labels)\n","np.save(fvalid_labels,valid_labels)"],"metadata":{"id":"4pmooxnmEw3O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.save(ftrain_x,nobbr_train_x)\n","np.save(ftest_x,nobbr_test_x)\n","np.save(fvalid_x,nobbr_valid_x)\n","np.save(ftrain_labels,nobbr_train_labels)\n","np.save(ftest_labels,nobbr_test_labels)\n","np.save(fvalid_labels,nobbr_valid_labels)"],"metadata":{"id":"g6IS6-38OLnN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.save(\"goodtrain\",train_good)\n","np.save(\"goodvalid\",valid_good)\n","np.save(\"goodtrainlabel\",train_good_labels)\n","np.save(\"goodvalidlabel\",valid_good_labels)"],"metadata":{"id":"ZPeHTgOPQhnM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Load the Train, Valid, Test Dataset "],"metadata":{"id":"8ma3azrkH35K"}},{"cell_type":"code","source":["ftrain_x=\"train_x\" \n","fvalid_x=\"valid_x\"\n","ftest_x=\"test_x\"\n","ftrain_labels =\"train_labels\"\n","fvalid_labels =\"valid_labels\"\n","ftest_labels=\"test_labels\""],"metadata":{"id":"dIVbey3_Gmck","executionInfo":{"status":"ok","timestamp":1677915857049,"user_tz":-540,"elapsed":5,"user":{"displayName":"궈노민","userId":"17233137132235511457"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["train_x=np.load(ftrain_x+\".npy\")\n","valid_x=np.load(fvalid_x+\".npy\")\n","test_x=np.load(ftest_x+\".npy\")\n","train_labels=np.load(ftrain_labels+\".npy\")\n","valid_labels=np.load(fvalid_labels+\".npy\")\n","test_labels=np.load(ftest_labels+\".npy\")"],"metadata":{"id":"5UE37C4eGfRB","executionInfo":{"status":"ok","timestamp":1677915881740,"user_tz":-540,"elapsed":22683,"user":{"displayName":"궈노민","userId":"17233137132235511457"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["nobbr_train_x=np.load(ftrain_x+\".npy\")\n","nobbr_valid_x=np.load(fvalid_x+\".npy\")\n","nobbr_test_x=np.load(ftest_x+\".npy\")\n","nobbr_train_labels=np.load(ftrain_labels+\".npy\")\n","nobbr_valid_labels=np.load(fvalid_labels+\".npy\")\n","nobbr_test_labels=np.load(ftest_labels+\".npy\")"],"metadata":{"id":"Wxa0L98JBXiI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(test_labels[68])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N6kmQL38lC-P","executionInfo":{"status":"ok","timestamp":1677915884603,"user_tz":-540,"elapsed":2,"user":{"displayName":"궈노민","userId":"17233137132235511457"}},"outputId":"3f424025-a2b0-4bc6-84bb-81661c2fe4a8"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["[[[0 0 1 0 0 0 0]]]\n"]}]},{"cell_type":"markdown","source":["## Model"],"metadata":{"id":"4Do_iXhyLm-u"}},{"cell_type":"markdown","source":["### Define Resnet block "],"metadata":{"id":"iiyucZzB2137"}},{"cell_type":"code","source":["def resblock(frames):\n","    #resblock에 들어온 input_layer\n","    input_layer=Input(shape=frames)\n","\n","    \n","    res_layer=Conv2D(filters=256,kernel_size=(1,3),strides=(1,2),padding='same')(input_layer)\n","    res_layer=BatchNormalization()(res_layer)\n","    \n","    \n","    conv1d_layer1=Conv2D(filters=256,kernel_size=(1,3),strides=(1,2),padding='same',kernel_regularizer=regularizers.L2(0.01))(input_layer)\n","    conv1d_layer1=BatchNormalization()(conv1d_layer1)\n","    conv1d_layer1=tf.keras.layers.ReLU()(conv1d_layer1)\n","\n","\n","    conv1d_layer1=Conv2D(filters=256,kernel_size=(1,3),strides=(1,1),padding='same')(conv1d_layer1)\n","    conv1d_layer1=BatchNormalization()(conv1d_layer1)\n","    conv1d_layer1=tf.keras.layers.ReLU()(conv1d_layer1)\n","\n","\n","    conv1d_layer1=Conv2D(filters=256,kernel_size=(1,3),strides=(1,1),padding='same')(conv1d_layer1)\n","    conv1d_layer1=BatchNormalization()(conv1d_layer1)\n","    conv1d_layer1=tf.keras.layers.ReLU()(conv1d_layer1)\n","\n","    conv1d_layer1=Dropout(0.2)(conv1d_layer1)\n","    \n","   \n","    output=tf.keras.layers.Add()([res_layer,conv1d_layer1])\n","    block=tf.keras.Model(inputs=input_layer,outputs=output)\n","    \n","    return block"],"metadata":{"id":"WBzAXpodOrwy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Reference Model"],"metadata":{"id":"7J3Xg0mv3Qs9"}},{"cell_type":"code","source":["def create_model():\n","    inputs=tf.keras.Input(shape=(171,300,1))\n","    layer1 = Conv2D(filters=256, kernel_size=(1, 3), strides=(1, 2),padding='same',kernel_regularizer=regularizers.L2(0.01))(inputs)\n","    layer1=BatchNormalization()(layer1)\n","    layer1=tf.keras.layers.ReLU()(layer1)\n","\n","    # (B,171,300,1) matrix를 (B.300,1) matrix 171 개로 찢어준다.\n","\n","    layer2=resblock((171,150,256))(layer1)\n","    layer3=resblock((171,75,256))(layer2)\n","    layer4=resblock((171,38,256))(layer3)\n","    layer5=resblock((171,19,256))(layer4)\n","\n","    layer6= AveragePooling2D(pool_size=(171,10),strides=(1,1),padding='valid')(layer5)\n","\n","    layer6=Dropout(0.2)(layer6)\n","    layer7=Conv2D(filters=7,kernel_size=(1,1),strides=(1,1))(layer6)\n","\n","    outputs=Softmax()(layer7)\n","\n","    my_model=tf.keras.Model(inputs=inputs,outputs=outputs)\n","\n","    return my_model"],"metadata":{"id":"6qKxAJTaEAXY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"nYAZn6Ujgk8L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dense Model"],"metadata":{"id":"oyzriNtC0sHB"}},{"cell_type":"code","source":["def create_dense():\n","    inputs=tf.keras.Input(shape=(171,300,1))\n","    layer1 = Conv2D(filters=256, kernel_size=(1, 3), strides=(1, 2),padding='same',kernel_regularizer=regularizers.L2(0.01))(inputs)\n","    layer1=BatchNormalization()(layer1)\n","    layer1=tf.keras.layers.ReLU()(layer1)\n","\n","    # (B,171,300,1) matrix를 (B.300,1) matrix 171 개로 찢어준다.\n","\n","    layer2=resblock((171,150,256))(layer1)\n","    layer3=resblock((171,75,256))(layer2)\n","    layer4=resblock((171,38,256))(layer3)\n","    layer5=resblock((171,19,256))(layer4)\n","\n","    layer6= tf.keras.layers.Flatten()(layer5)\n","    print(layer6.shape)\n","\n","    layer6=Dropout(0.2)(layer6)\n","    layer7=tf.keras.layers.Dense(7)(layer6)\n","    layer7=Softmax()(layer7)\n","\n","    outputs=tf.keras.layers.Reshape((1,1,7), input_shape=(7,))(layer7)\n","  \n","    print(outputs.shape)\n","    my_model=tf.keras.Model(inputs=inputs,outputs=outputs)\n","\n","    return my_model"],"metadata":{"id":"fc61dcbZ0vcC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["d_model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oMl3Ln-natto","executionInfo":{"status":"ok","timestamp":1677896391147,"user_tz":-540,"elapsed":535,"user":{"displayName":"­권오민 / 학생 / 전기·정보공학부","userId":"14836171550716712824"}},"outputId":"7f36eac5-9d43-4994-e068-e6df608eb905"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_9\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_6 (InputLayer)        [(None, 171, 300, 1)]     0         \n","                                                                 \n"," conv2d_17 (Conv2D)          (None, 171, 150, 256)     1024      \n","                                                                 \n"," batch_normalization_17 (Bat  (None, 171, 150, 256)    1024      \n"," chNormalization)                                                \n","                                                                 \n"," re_lu_13 (ReLU)             (None, 171, 150, 256)     0         \n","                                                                 \n"," model_5 (Functional)        (None, 171, 75, 256)      791552    \n","                                                                 \n"," model_6 (Functional)        (None, 171, 38, 256)      791552    \n","                                                                 \n"," model_7 (Functional)        (None, 171, 19, 256)      791552    \n","                                                                 \n"," model_8 (Functional)        (None, 171, 10, 256)      791552    \n","                                                                 \n"," flatten_1 (Flatten)         (None, 437760)            0         \n","                                                                 \n"," dropout_9 (Dropout)         (None, 437760)            0         \n","                                                                 \n"," dense_1 (Dense)             (None, 7)                 3064327   \n","                                                                 \n"," softmax_1 (Softmax)         (None, 7)                 0         \n","                                                                 \n"," reshape_1 (Reshape)         (None, 1, 1, 7)           0         \n","                                                                 \n","=================================================================\n","Total params: 6,232,583\n","Trainable params: 6,223,879\n","Non-trainable params: 8,704\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["## Train the Model\n"],"metadata":{"id":"O9sb2RjF4Ufp"}},{"cell_type":"markdown","source":["### Training Reference Model"],"metadata":{"id":"7QvBpL85413Z"}},{"cell_type":"code","source":["\n","\n","initial_learning_rate=0.01\n","lr_schedule=tf.keras.optimizers.schedules.ExponentialDecay(\n","    initial_learning_rate,\n","    decay_steps=100000,\n","    decay_rate=0.96,\n","    staircase=True\n",")\n","\n","\n","# 체크포인트 콜백 만들기\n","\n","callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n","                                           patience=5),\n","             tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n","                                             monitor='val_loss',\n","                                             save_weights_only=True,\n","                                             save_best_only=True,verbose=2)]\n","\n","my_model=create_model()\n","my_model.compile(optimizer=tf.keras.optimizers.Adadelta(learning_rate=lr_schedule),loss='categorical_crossentropy',metrics=['accuracy'])\n","my_model.summary()"],"metadata":{"id":"zmrd9Xy28kpk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["my_model.fit(x=train_x,y=train_labels,batch_size=16,epochs=60,validation_data=(valid_x,valid_labels),verbose=2, callbacks = [callbacks])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hjnnv4ce7Pvs","outputId":"addd27e5-bcab-48bf-cc0a-2d3ce998aee8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/60\n"]}]},{"cell_type":"markdown","source":["#### CheckPoint Training"],"metadata":{"id":"sp1BN44HBYMe"}},{"cell_type":"code","source":["# checkpoint_path로 부터 model을 받아와서 loading\n","test_labels=test_labels.reshape((-1,1,1,7))\n","initial_learning_rate=0.006\n","lr_schedule=tf.keras.optimizers.schedules.ExponentialDecay(\n","    initial_learning_rate,\n","    decay_steps=100000,\n","    decay_rate=0.96,\n","    staircase=True\n",")\n","\n","\n","my_model=create_model()\n","my_model.compile(optimizer=tf.keras.optimizers.Adadelta(learning_rate=lr_schedule),loss='categorical_crossentropy',metrics=['accuracy'])\n","my_model.load_weights(checkpoint_path)\n","loss,acc = my_model.evaluate(test_x,test_labels, verbose=2)"],"metadata":{"id":"mRA1xADhArES","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677897977387,"user_tz":-540,"elapsed":8415,"user":{"displayName":"­권오민 / 학생 / 전기·정보공학부","userId":"14836171550716712824"}},"outputId":"0ad4ce44-ef15-4a4d-c627-aadbab4c504b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["7/7 - 3s - loss: 4.7772 - accuracy: 0.7222 - 3s/epoch - 489ms/step\n"]}]},{"cell_type":"code","source":["my_model.summary()"],"metadata":{"id":"Hgp2d8Y_g98d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#checkpoint2에다가 저장함. checkpoint2에는 69퍼센트까지 늘린 모델 저장되어 있음.\n","callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n","                                           patience=8),\n","             tf.keras.callbacks.ModelCheckpoint(checkpoint_path2,\n","                                             monitor='val_loss',\n","                                             save_weights_only=True,\n","                                             save_best_only=True,verbose=2),\n","             ]\n","\n","my_model.fit(x=train_x,y=train_labels,batch_size=16,epochs=60,validation_data=(valid_x,valid_labels),verbose=2, callbacks = [callbacks])\n"],"metadata":{"id":"0kHY1tRV99YH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Training Dense Model"],"metadata":{"id":"mrImGTFi5NBA"}},{"cell_type":"code","source":["d_model=create_dense()\n","d_model.summary()"],"metadata":{"id":"EELrlNl25wD-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["initial_learning_rate=0.01\n","lr_schedule=tf.keras.optimizers.schedules.ExponentialDecay(\n","    initial_learning_rate,\n","    decay_steps=1000000,\n","    decay_rate=0.96,\n","    staircase=True\n",")\n","\n","\n","# 체크포인트 콜백 만들기\n","\n","callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n","                                           patience=5),\n","             tf.keras.callbacks.ModelCheckpoint(checkpoint_path3,\n","                                             monitor='val_loss',\n","                                             save_weights_only=True,\n","                                             save_best_only=True,verbose=2)]\n","\n","d_model.compile(optimizer=tf.keras.optimizers.Adadelta(learning_rate=lr_schedule),loss='categorical_crossentropy',metrics=['accuracy'])\n","d_model.fit(x=train_x,y=train_labels,batch_size=16,epochs=60,validation_data=(valid_x,valid_labels),verbose=2, callbacks = [callbacks])"],"metadata":{"id":"q0e5v-Wl5Pw7","colab":{"base_uri":"https://localhost:8080/"},"outputId":"af78ed23-89c9-4fe7-c49b-24d7bc377d7d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/60\n","\n","Epoch 1: val_loss improved from inf to 11.66981, saving model to ck3/cp.ckpt\n","180/180 - 244s - loss: 11.4831 - accuracy: 0.6004 - val_loss: 11.6698 - val_accuracy: 0.4931 - 244s/epoch - 1s/step\n","Epoch 2/60\n","\n","Epoch 2: val_loss improved from 11.66981 to 11.64566, saving model to ck3/cp.ckpt\n","180/180 - 195s - loss: 11.0830 - accuracy: 0.6803 - val_loss: 11.6457 - val_accuracy: 0.5305 - 195s/epoch - 1s/step\n","Epoch 3/60\n","\n","Epoch 3: val_loss improved from 11.64566 to 11.63276, saving model to ck3/cp.ckpt\n","180/180 - 194s - loss: 10.9406 - accuracy: 0.7179 - val_loss: 11.6328 - val_accuracy: 0.5166 - 194s/epoch - 1s/step\n","Epoch 4/60\n","\n","Epoch 4: val_loss improved from 11.63276 to 11.44734, saving model to ck3/cp.ckpt\n","180/180 - 195s - loss: 10.7726 - accuracy: 0.7467 - val_loss: 11.4473 - val_accuracy: 0.5471 - 195s/epoch - 1s/step\n","Epoch 5/60\n","\n","Epoch 5: val_loss improved from 11.44734 to 11.38552, saving model to ck3/cp.ckpt\n","180/180 - 195s - loss: 10.6360 - accuracy: 0.7804 - val_loss: 11.3855 - val_accuracy: 0.5665 - 195s/epoch - 1s/step\n","Epoch 6/60\n","\n","Epoch 6: val_loss improved from 11.38552 to 11.38051, saving model to ck3/cp.ckpt\n","180/180 - 194s - loss: 10.5419 - accuracy: 0.7985 - val_loss: 11.3805 - val_accuracy: 0.5596 - 194s/epoch - 1s/step\n","Epoch 7/60\n","\n","Epoch 7: val_loss improved from 11.38051 to 11.08914, saving model to ck3/cp.ckpt\n","180/180 - 195s - loss: 10.4159 - accuracy: 0.8238 - val_loss: 11.0891 - val_accuracy: 0.6039 - 195s/epoch - 1s/step\n","Epoch 8/60\n","\n","Epoch 8: val_loss did not improve from 11.08914\n","180/180 - 194s - loss: 10.2866 - accuracy: 0.8586 - val_loss: 11.2487 - val_accuracy: 0.6094 - 194s/epoch - 1s/step\n","Epoch 9/60\n","\n","Epoch 9: val_loss did not improve from 11.08914\n","180/180 - 194s - loss: 10.1929 - accuracy: 0.8700 - val_loss: 11.2365 - val_accuracy: 0.5914 - 194s/epoch - 1s/step\n","Epoch 10/60\n","\n","Epoch 10: val_loss improved from 11.08914 to 11.02102, saving model to ck3/cp.ckpt\n","180/180 - 195s - loss: 10.0848 - accuracy: 0.8905 - val_loss: 11.0210 - val_accuracy: 0.6163 - 195s/epoch - 1s/step\n","Epoch 11/60\n","\n","Epoch 11: val_loss improved from 11.02102 to 10.89637, saving model to ck3/cp.ckpt\n","180/180 - 194s - loss: 10.0401 - accuracy: 0.8874 - val_loss: 10.8964 - val_accuracy: 0.6233 - 194s/epoch - 1s/step\n","Epoch 12/60\n","\n","Epoch 12: val_loss did not improve from 10.89637\n","180/180 - 194s - loss: 9.9219 - accuracy: 0.9170 - val_loss: 11.1011 - val_accuracy: 0.5928 - 194s/epoch - 1s/step\n","Epoch 13/60\n","\n","Epoch 13: val_loss did not improve from 10.89637\n","180/180 - 194s - loss: 9.8338 - accuracy: 0.9281 - val_loss: 10.9707 - val_accuracy: 0.6205 - 194s/epoch - 1s/step\n","Epoch 14/60\n","\n","Epoch 14: val_loss did not improve from 10.89637\n","180/180 - 194s - loss: 9.7365 - accuracy: 0.9430 - val_loss: 10.8978 - val_accuracy: 0.5956 - 194s/epoch - 1s/step\n","Epoch 15/60\n","\n","Epoch 15: val_loss improved from 10.89637 to 10.71895, saving model to ck3/cp.ckpt\n","180/180 - 195s - loss: 9.6817 - accuracy: 0.9361 - val_loss: 10.7189 - val_accuracy: 0.6260 - 195s/epoch - 1s/step\n","Epoch 16/60\n","\n","Epoch 16: val_loss did not improve from 10.71895\n","180/180 - 194s - loss: 9.5926 - accuracy: 0.9472 - val_loss: 10.7472 - val_accuracy: 0.6302 - 194s/epoch - 1s/step\n","Epoch 17/60\n","\n","Epoch 17: val_loss improved from 10.71895 to 10.68639, saving model to ck3/cp.ckpt\n","180/180 - 194s - loss: 9.4945 - accuracy: 0.9593 - val_loss: 10.6864 - val_accuracy: 0.6274 - 194s/epoch - 1s/step\n","Epoch 18/60\n","\n","Epoch 18: val_loss did not improve from 10.68639\n","180/180 - 194s - loss: 9.4210 - accuracy: 0.9618 - val_loss: 10.8080 - val_accuracy: 0.6122 - 194s/epoch - 1s/step\n","Epoch 19/60\n","\n","Epoch 19: val_loss did not improve from 10.68639\n","180/180 - 194s - loss: 9.3275 - accuracy: 0.9736 - val_loss: 10.7826 - val_accuracy: 0.5886 - 194s/epoch - 1s/step\n","Epoch 20/60\n","\n","Epoch 20: val_loss improved from 10.68639 to 10.51339, saving model to ck3/cp.ckpt\n","180/180 - 195s - loss: 9.2518 - accuracy: 0.9715 - val_loss: 10.5134 - val_accuracy: 0.6150 - 195s/epoch - 1s/step\n","Epoch 21/60\n","\n","Epoch 21: val_loss improved from 10.51339 to 10.38194, saving model to ck3/cp.ckpt\n","180/180 - 194s - loss: 9.1509 - accuracy: 0.9785 - val_loss: 10.3819 - val_accuracy: 0.6108 - 194s/epoch - 1s/step\n","Epoch 22/60\n","\n","Epoch 22: val_loss did not improve from 10.38194\n","180/180 - 194s - loss: 9.0678 - accuracy: 0.9785 - val_loss: 10.4301 - val_accuracy: 0.6316 - 194s/epoch - 1s/step\n","Epoch 23/60\n","\n","Epoch 23: val_loss improved from 10.38194 to 10.34947, saving model to ck3/cp.ckpt\n","180/180 - 195s - loss: 8.9754 - accuracy: 0.9833 - val_loss: 10.3495 - val_accuracy: 0.6053 - 195s/epoch - 1s/step\n","Epoch 24/60\n","\n","Epoch 24: val_loss did not improve from 10.34947\n","180/180 - 194s - loss: 8.8824 - accuracy: 0.9882 - val_loss: 10.3584 - val_accuracy: 0.6053 - 194s/epoch - 1s/step\n","Epoch 25/60\n","\n","Epoch 25: val_loss improved from 10.34947 to 10.13439, saving model to ck3/cp.ckpt\n","180/180 - 195s - loss: 8.7775 - accuracy: 0.9892 - val_loss: 10.1344 - val_accuracy: 0.6094 - 195s/epoch - 1s/step\n","Epoch 26/60\n","\n","Epoch 26: val_loss improved from 10.13439 to 9.99307, saving model to ck3/cp.ckpt\n","180/180 - 195s - loss: 8.6882 - accuracy: 0.9864 - val_loss: 9.9931 - val_accuracy: 0.6413 - 195s/epoch - 1s/step\n","Epoch 27/60\n","\n","Epoch 27: val_loss did not improve from 9.99307\n","180/180 - 194s - loss: 8.5795 - accuracy: 0.9931 - val_loss: 10.0188 - val_accuracy: 0.6094 - 194s/epoch - 1s/step\n","Epoch 28/60\n","\n","Epoch 28: val_loss did not improve from 9.99307\n","180/180 - 194s - loss: 8.4708 - accuracy: 0.9927 - val_loss: 10.0062 - val_accuracy: 0.6163 - 194s/epoch - 1s/step\n","Epoch 29/60\n","\n","Epoch 29: val_loss improved from 9.99307 to 9.93761, saving model to ck3/cp.ckpt\n","180/180 - 195s - loss: 8.3652 - accuracy: 0.9896 - val_loss: 9.9376 - val_accuracy: 0.6136 - 195s/epoch - 1s/step\n","Epoch 30/60\n","\n","Epoch 30: val_loss improved from 9.93761 to 9.59400, saving model to ck3/cp.ckpt\n","180/180 - 195s - loss: 8.2549 - accuracy: 0.9937 - val_loss: 9.5940 - val_accuracy: 0.6385 - 195s/epoch - 1s/step\n","Epoch 31/60\n","\n","Epoch 31: val_loss improved from 9.59400 to 9.48631, saving model to ck3/cp.ckpt\n","180/180 - 195s - loss: 8.1354 - accuracy: 0.9965 - val_loss: 9.4863 - val_accuracy: 0.6316 - 195s/epoch - 1s/step\n","Epoch 32/60\n","\n","Epoch 32: val_loss improved from 9.48631 to 9.41184, saving model to ck3/cp.ckpt\n","180/180 - 195s - loss: 8.0333 - accuracy: 0.9917 - val_loss: 9.4118 - val_accuracy: 0.6399 - 195s/epoch - 1s/step\n","Epoch 33/60\n","\n","Epoch 33: val_loss improved from 9.41184 to 9.37014, saving model to ck3/cp.ckpt\n","180/180 - 194s - loss: 7.9211 - accuracy: 0.9948 - val_loss: 9.3701 - val_accuracy: 0.6219 - 194s/epoch - 1s/step\n","Epoch 34/60\n","\n","Epoch 34: val_loss improved from 9.37014 to 9.27231, saving model to ck3/cp.ckpt\n","180/180 - 194s - loss: 7.8085 - accuracy: 0.9969 - val_loss: 9.2723 - val_accuracy: 0.6233 - 194s/epoch - 1s/step\n","Epoch 35/60\n","\n","Epoch 35: val_loss improved from 9.27231 to 9.07173, saving model to ck3/cp.ckpt\n","180/180 - 195s - loss: 7.6914 - accuracy: 0.9955 - val_loss: 9.0717 - val_accuracy: 0.6343 - 195s/epoch - 1s/step\n","Epoch 36/60\n","\n","Epoch 36: val_loss improved from 9.07173 to 8.97512, saving model to ck3/cp.ckpt\n","180/180 - 194s - loss: 7.5729 - accuracy: 0.9962 - val_loss: 8.9751 - val_accuracy: 0.6427 - 194s/epoch - 1s/step\n","Epoch 37/60\n","\n","Epoch 37: val_loss improved from 8.97512 to 8.78477, saving model to ck3/cp.ckpt\n","180/180 - 195s - loss: 7.4562 - accuracy: 0.9962 - val_loss: 8.7848 - val_accuracy: 0.6524 - 195s/epoch - 1s/step\n","Epoch 38/60\n","\n","Epoch 38: val_loss did not improve from 8.78477\n","180/180 - 194s - loss: 7.3386 - accuracy: 0.9986 - val_loss: 8.9168 - val_accuracy: 0.6274 - 194s/epoch - 1s/step\n","Epoch 39/60\n","\n","Epoch 39: val_loss improved from 8.78477 to 8.56573, saving model to ck3/cp.ckpt\n","180/180 - 195s - loss: 7.2148 - accuracy: 0.9979 - val_loss: 8.5657 - val_accuracy: 0.6524 - 195s/epoch - 1s/step\n","Epoch 40/60\n","\n","Epoch 40: val_loss improved from 8.56573 to 8.47122, saving model to ck3/cp.ckpt\n","180/180 - 195s - loss: 7.0802 - accuracy: 0.9990 - val_loss: 8.4712 - val_accuracy: 0.6385 - 195s/epoch - 1s/step\n","Epoch 41/60\n"]}]},{"cell_type":"code","source":["d_model.save(\"cid_epoch40_72_real.h5\")"],"metadata":{"id":"M_7iYXyGUyJe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### CheckPoint Training"],"metadata":{"id":"BKH9fW7XR2f2"}},{"cell_type":"code","source":["# checkpoint_path4로 부터 model을 받아와서 loading\n","nobbr_test_labels=nobbr_test_labels.reshape((-1,1,1,7))\n","initial_learning_rate=0.01\n","lr_schedule=tf.keras.optimizers.schedules.ExponentialDecay(\n","    initial_learning_rate,\n","    decay_steps=100000,\n","    decay_rate=0.96,\n","    staircase=True\n",")\n","\n","\n","d_model=create_dense()\n","d_model.compile(optimizer=tf.keras.optimizers.Adadelta(learning_rate=lr_schedule),loss='categorical_crossentropy',metrics=['accuracy'])\n","d_model.load_weights(checkpoint_path3)\n","d_model.evaluate(test_x,test_labels,verbose=2)"],"metadata":{"id":"qBuRm8KODeMt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677906951806,"user_tz":-540,"elapsed":208829,"user":{"displayName":"­권오민 / 학생 / 전기·정보공학부","userId":"14836171550716712824"}},"outputId":"ce751b32-2b1d-48e0-81a3-e3eb2085257c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(None, 437760)\n","(None, 1, 1, 7)\n","7/7 - 188s - loss: 3.1258 - accuracy: 0.7323 - 188s/epoch - 27s/step\n"]},{"output_type":"execute_result","data":{"text/plain":["[3.1258485317230225, 0.7323232293128967]"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["d_model.save(\"0304_goodemph60.h5\")"],"metadata":{"id":"_MIvvx0FHNye","executionInfo":{"status":"error","timestamp":1677905987615,"user_tz":-540,"elapsed":344,"user":{"displayName":"­권오민 / 학생 / 전기·정보공학부","userId":"14836171550716712824"}},"colab":{"base_uri":"https://localhost:8080/","height":170},"outputId":"8075c8b8-1fb7-4260-d6c6-4d34ad45a54a"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-4a91f3792e7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"0304_goodemph60.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'd_model' is not defined"]}]},{"cell_type":"code","source":["!pip install tensorflowjs"],"metadata":{"id":"qxifzT_HHccd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677906997698,"user_tz":-540,"elapsed":14640,"user":{"displayName":"­권오민 / 학생 / 전기·정보공학부","userId":"14836171550716712824"}},"outputId":"65a6bfeb-c7f8-4503-d5c5-f22549fba317"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflowjs\n","  Downloading tensorflowjs-4.2.0-py3-none-any.whl (84 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 KB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting flax>=0.6.2\n","  Downloading flax-0.6.6-py3-none-any.whl (210 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.1/210.1 KB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflowjs) (3.19.6)\n","Collecting tensorflow-decision-forests>=1.0.1\n","  Downloading tensorflow_decision_forests-1.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorflow<3,>=2.10.0 in /usr/local/lib/python3.8/dist-packages (from tensorflowjs) (2.11.0)\n","Requirement already satisfied: importlib_resources>=5.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflowjs) (5.12.0)\n","Requirement already satisfied: jax>=0.3.16 in /usr/local/lib/python3.8/dist-packages (from tensorflowjs) (0.4.4)\n","Requirement already satisfied: tensorflow-hub<0.13,>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from tensorflowjs) (0.12.0)\n","Collecting packaging~=20.9\n","  Downloading packaging-20.9-py2.py3-none-any.whl (40 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 KB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six<2,>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflowjs) (1.15.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from flax>=0.6.2->tensorflowjs) (3.5.3)\n","Collecting optax\n","  Downloading optax-0.1.4-py3-none-any.whl (154 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.9/154.9 KB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorstore\n","  Downloading tensorstore-0.1.33-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting orbax\n","  Downloading orbax-0.1.3-py3-none-any.whl (74 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.2/74.2 KB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: msgpack in /usr/local/lib/python3.8/dist-packages (from flax>=0.6.2->tensorflowjs) (1.0.4)\n","Collecting rich>=11.1\n","  Downloading rich-13.3.1-py3-none-any.whl (239 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.0/239.0 KB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.8/dist-packages (from flax>=0.6.2->tensorflowjs) (4.5.0)\n","Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.8/dist-packages (from flax>=0.6.2->tensorflowjs) (6.0)\n","Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.8/dist-packages (from flax>=0.6.2->tensorflowjs) (1.22.4)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib_resources>=5.9.0->tensorflowjs) (3.15.0)\n","Requirement already satisfied: opt-einsum in /usr/local/lib/python3.8/dist-packages (from jax>=0.3.16->tensorflowjs) (3.3.0)\n","Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.8/dist-packages (from jax>=0.3.16->tensorflowjs) (1.10.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging~=20.9->tensorflowjs) (3.0.9)\n","Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3,>=2.10.0->tensorflowjs) (2.11.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3,>=2.10.0->tensorflowjs) (1.6.3)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3,>=2.10.0->tensorflowjs) (23.1.21)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3,>=2.10.0->tensorflowjs) (1.15.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3,>=2.10.0->tensorflowjs) (0.31.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3,>=2.10.0->tensorflowjs) (15.0.6.1)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3,>=2.10.0->tensorflowjs) (2.2.0)\n","Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3,>=2.10.0->tensorflowjs) (2.11.2)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3,>=2.10.0->tensorflowjs) (3.1.0)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3,>=2.10.0->tensorflowjs) (0.4.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3,>=2.10.0->tensorflowjs) (1.4.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3,>=2.10.0->tensorflowjs) (1.51.3)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3,>=2.10.0->tensorflowjs) (0.2.0)\n","Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3,>=2.10.0->tensorflowjs) (2.11.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow<3,>=2.10.0->tensorflowjs) (57.4.0)\n","Collecting wurlitzer\n","  Downloading wurlitzer-3.0.3-py3-none-any.whl (7.3 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from tensorflow-decision-forests>=1.0.1->tensorflowjs) (1.3.5)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from tensorflow-decision-forests>=1.0.1->tensorflowjs) (0.38.4)\n","Collecting pygments<3.0.0,>=2.14.0\n","  Downloading Pygments-2.14.0-py3-none-any.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting markdown-it-py<3.0.0,>=2.1.0\n","  Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 KB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (2.2.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (2.25.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (1.8.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (0.6.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (2.16.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (3.4.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib->flax>=0.6.2->tensorflowjs) (2.8.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->flax>=0.6.2->tensorflowjs) (8.4.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->flax>=0.6.2->tensorflowjs) (4.38.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->flax>=0.6.2->tensorflowjs) (1.4.4)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->flax>=0.6.2->tensorflowjs) (0.11.0)\n","Collecting chex>=0.1.5\n","  Downloading chex-0.1.6-py3-none-any.whl (87 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.9/87.9 KB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.8/dist-packages (from optax->flax>=0.6.2->tensorflowjs) (0.4.4+cuda11.cudnn82)\n","Requirement already satisfied: etils in /usr/local/lib/python3.8/dist-packages (from orbax->flax>=0.6.2->tensorflowjs) (1.0.0)\n","Collecting cached_property\n","  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->tensorflow-decision-forests>=1.0.1->tensorflowjs) (2022.7.1)\n","Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from chex>=0.1.5->optax->flax>=0.6.2->tensorflowjs) (0.12.0)\n","Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.8/dist-packages (from chex>=0.1.5->optax->flax>=0.6.2->tensorflowjs) (0.1.8)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (5.3.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (6.0.0)\n","Collecting mdurl~=0.1\n","  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (2022.12.7)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (4.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (1.26.14)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (2.1.2)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<3,>=2.10.0->tensorflowjs) (3.2.2)\n","Installing collected packages: cached_property, wurlitzer, tensorstore, pygments, packaging, mdurl, markdown-it-py, rich, chex, optax, tensorflow-decision-forests, orbax, flax, tensorflowjs\n","  Attempting uninstall: pygments\n","    Found existing installation: Pygments 2.6.1\n","    Uninstalling Pygments-2.6.1:\n","      Successfully uninstalled Pygments-2.6.1\n","  Attempting uninstall: packaging\n","    Found existing installation: packaging 23.0\n","    Uninstalling packaging-23.0:\n","      Successfully uninstalled packaging-23.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ipython 7.9.0 requires jedi>=0.10, which is not installed.\n","xarray 2022.12.0 requires packaging>=21.3, but you have packaging 20.9 which is incompatible.\n","statsmodels 0.13.5 requires packaging>=21.3, but you have packaging 20.9 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed cached_property-1.5.2 chex-0.1.6 flax-0.6.6 markdown-it-py-2.2.0 mdurl-0.1.2 optax-0.1.4 orbax-0.1.3 packaging-20.9 pygments-2.14.0 rich-13.3.1 tensorflow-decision-forests-1.2.0 tensorflowjs-4.2.0 tensorstore-0.1.33 wurlitzer-3.0.3\n"]}]},{"cell_type":"code","source":["!tensorflowjs_converter --input_format keras --weight_shard_size_bytes 30000000 \"./0304_goodemph60.h5\" \"./\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MoitlhLHHR9s","executionInfo":{"status":"ok","timestamp":1677907030058,"user_tz":-540,"elapsed":19764,"user":{"displayName":"­권오민 / 학생 / 전기·정보공학부","userId":"14836171550716712824"}},"outputId":"6c15ad37-edf5-40ea-936d-8cb92fb9472e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-03-04 05:16:56.999567: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n","2023-03-04 05:16:56.999788: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n","2023-03-04 05:16:56.999819: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"]}]},{"cell_type":"code","source":["#checkpoint3에다가 nobbr을 더 잘 detect 하는 저장함. checkpoint4에는 전체로 training 한 모델 저장되어 있음.\n","callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n","                                           patience=5),\n","             tf.keras.callbacks.ModelCheckpoint(checkpoint_path3,\n","                                             monitor='val_loss',\n","                                             save_weights_only=True,\n","                                             save_best_only=True,verbose=2),\n","             ]\n","\n","d_model.fit(x=nobbr_train_x,y=nobbr_train_labels,batch_size=16,epochs=60,validation_data=(nobbr_valid_x,nobbr_valid_labels),verbose=2, callbacks = [callbacks])"],"metadata":{"id":"zhjsO5fQDhW0","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1677905007731,"user_tz":-540,"elapsed":3374363,"user":{"displayName":"­권오민 / 학생 / 전기·정보공학부","userId":"14836171550716712824"}},"outputId":"e9f7dcc9-3ad5-4d46-8fd0-bca80f6d0db0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/60\n","\n","Epoch 1: val_loss improved from inf to 6.12028, saving model to ck3/cp.ckpt\n","51/51 - 70s - loss: 4.4225 - accuracy: 1.0000 - val_loss: 6.1203 - val_accuracy: 0.6154 - 70s/epoch - 1s/step\n","Epoch 2/60\n","\n","Epoch 2: val_loss improved from 6.12028 to 6.08312, saving model to ck3/cp.ckpt\n","51/51 - 61s - loss: 4.3854 - accuracy: 0.9988 - val_loss: 6.0831 - val_accuracy: 0.6058 - 61s/epoch - 1s/step\n","Epoch 3/60\n","\n","Epoch 3: val_loss did not improve from 6.08312\n","51/51 - 60s - loss: 4.3460 - accuracy: 1.0000 - val_loss: 6.1720 - val_accuracy: 0.5769 - 60s/epoch - 1s/step\n","Epoch 4/60\n","\n","Epoch 4: val_loss improved from 6.08312 to 6.01823, saving model to ck3/cp.ckpt\n","51/51 - 60s - loss: 4.2964 - accuracy: 1.0000 - val_loss: 6.0182 - val_accuracy: 0.6010 - 60s/epoch - 1s/step\n","Epoch 5/60\n","\n","Epoch 5: val_loss improved from 6.01823 to 5.92493, saving model to ck3/cp.ckpt\n","51/51 - 60s - loss: 4.2450 - accuracy: 1.0000 - val_loss: 5.9249 - val_accuracy: 0.6106 - 60s/epoch - 1s/step\n","Epoch 6/60\n","\n","Epoch 6: val_loss did not improve from 5.92493\n","51/51 - 60s - loss: 4.1894 - accuracy: 1.0000 - val_loss: 5.9531 - val_accuracy: 0.5817 - 60s/epoch - 1s/step\n","Epoch 7/60\n","\n","Epoch 7: val_loss improved from 5.92493 to 5.67359, saving model to ck3/cp.ckpt\n","51/51 - 60s - loss: 4.1287 - accuracy: 1.0000 - val_loss: 5.6736 - val_accuracy: 0.6538 - 60s/epoch - 1s/step\n","Epoch 8/60\n","\n","Epoch 8: val_loss did not improve from 5.67359\n","51/51 - 60s - loss: 4.0755 - accuracy: 1.0000 - val_loss: 6.0484 - val_accuracy: 0.5625 - 60s/epoch - 1s/step\n","Epoch 9/60\n","\n","Epoch 9: val_loss did not improve from 5.67359\n","51/51 - 58s - loss: 4.0228 - accuracy: 1.0000 - val_loss: 5.6876 - val_accuracy: 0.6202 - 58s/epoch - 1s/step\n","Epoch 10/60\n","\n","Epoch 10: val_loss did not improve from 5.67359\n","51/51 - 60s - loss: 3.9642 - accuracy: 1.0000 - val_loss: 5.7437 - val_accuracy: 0.5913 - 60s/epoch - 1s/step\n","Epoch 11/60\n","\n","Epoch 11: val_loss did not improve from 5.67359\n","51/51 - 60s - loss: 3.9001 - accuracy: 1.0000 - val_loss: 5.7269 - val_accuracy: 0.6010 - 60s/epoch - 1s/step\n","Epoch 12/60\n","\n","Epoch 12: val_loss improved from 5.67359 to 5.51275, saving model to ck3/cp.ckpt\n","51/51 - 58s - loss: 3.8343 - accuracy: 1.0000 - val_loss: 5.5127 - val_accuracy: 0.6202 - 58s/epoch - 1s/step\n","Epoch 13/60\n","\n","Epoch 13: val_loss did not improve from 5.51275\n","51/51 - 60s - loss: 3.7758 - accuracy: 1.0000 - val_loss: 5.5884 - val_accuracy: 0.6010 - 60s/epoch - 1s/step\n","Epoch 14/60\n","\n","Epoch 14: val_loss improved from 5.51275 to 5.49595, saving model to ck3/cp.ckpt\n","51/51 - 60s - loss: 3.7255 - accuracy: 1.0000 - val_loss: 5.4960 - val_accuracy: 0.5913 - 60s/epoch - 1s/step\n","Epoch 15/60\n","\n","Epoch 15: val_loss improved from 5.49595 to 5.25144, saving model to ck3/cp.ckpt\n","51/51 - 60s - loss: 3.6761 - accuracy: 1.0000 - val_loss: 5.2514 - val_accuracy: 0.6442 - 60s/epoch - 1s/step\n","Epoch 16/60\n","\n","Epoch 16: val_loss did not improve from 5.25144\n","51/51 - 60s - loss: 3.6210 - accuracy: 1.0000 - val_loss: 5.3246 - val_accuracy: 0.6058 - 60s/epoch - 1s/step\n","Epoch 17/60\n","\n","Epoch 17: val_loss did not improve from 5.25144\n","51/51 - 58s - loss: 3.5613 - accuracy: 1.0000 - val_loss: 5.3629 - val_accuracy: 0.6010 - 58s/epoch - 1s/step\n","Epoch 18/60\n","\n","Epoch 18: val_loss did not improve from 5.25144\n","51/51 - 60s - loss: 3.5019 - accuracy: 1.0000 - val_loss: 5.3324 - val_accuracy: 0.6010 - 60s/epoch - 1s/step\n","Epoch 19/60\n","\n","Epoch 19: val_loss did not improve from 5.25144\n","51/51 - 60s - loss: 3.4425 - accuracy: 1.0000 - val_loss: 5.3553 - val_accuracy: 0.5577 - 60s/epoch - 1s/step\n","Epoch 20/60\n","\n","Epoch 20: val_loss improved from 5.25144 to 5.05895, saving model to ck3/cp.ckpt\n","51/51 - 60s - loss: 3.3823 - accuracy: 1.0000 - val_loss: 5.0589 - val_accuracy: 0.5962 - 60s/epoch - 1s/step\n","Epoch 21/60\n","\n","Epoch 21: val_loss did not improve from 5.05895\n","51/51 - 60s - loss: 3.3245 - accuracy: 1.0000 - val_loss: 5.1577 - val_accuracy: 0.5865 - 60s/epoch - 1s/step\n","Epoch 22/60\n","\n","Epoch 22: val_loss did not improve from 5.05895\n","51/51 - 59s - loss: 3.2687 - accuracy: 1.0000 - val_loss: 5.0594 - val_accuracy: 0.6106 - 59s/epoch - 1s/step\n","Epoch 23/60\n","\n","Epoch 23: val_loss improved from 5.05895 to 4.98124, saving model to ck3/cp.ckpt\n","51/51 - 60s - loss: 3.2116 - accuracy: 1.0000 - val_loss: 4.9812 - val_accuracy: 0.6058 - 60s/epoch - 1s/step\n","Epoch 24/60\n","\n","Epoch 24: val_loss improved from 4.98124 to 4.82599, saving model to ck3/cp.ckpt\n","51/51 - 58s - loss: 3.1541 - accuracy: 1.0000 - val_loss: 4.8260 - val_accuracy: 0.6442 - 58s/epoch - 1s/step\n","Epoch 25/60\n","\n","Epoch 25: val_loss improved from 4.82599 to 4.77816, saving model to ck3/cp.ckpt\n","51/51 - 58s - loss: 3.0992 - accuracy: 1.0000 - val_loss: 4.7782 - val_accuracy: 0.6298 - 58s/epoch - 1s/step\n","Epoch 26/60\n","\n","Epoch 26: val_loss improved from 4.77816 to 4.69042, saving model to ck3/cp.ckpt\n","51/51 - 58s - loss: 3.0469 - accuracy: 1.0000 - val_loss: 4.6904 - val_accuracy: 0.6250 - 58s/epoch - 1s/step\n","Epoch 27/60\n","\n","Epoch 27: val_loss did not improve from 4.69042\n","51/51 - 58s - loss: 2.9964 - accuracy: 1.0000 - val_loss: 4.8060 - val_accuracy: 0.6154 - 58s/epoch - 1s/step\n","Epoch 28/60\n","\n","Epoch 28: val_loss improved from 4.69042 to 4.67199, saving model to ck3/cp.ckpt\n","51/51 - 60s - loss: 2.9464 - accuracy: 1.0000 - val_loss: 4.6720 - val_accuracy: 0.5865 - 60s/epoch - 1s/step\n","Epoch 29/60\n","\n","Epoch 29: val_loss did not improve from 4.67199\n","51/51 - 60s - loss: 2.8951 - accuracy: 1.0000 - val_loss: 4.7565 - val_accuracy: 0.5913 - 60s/epoch - 1s/step\n","Epoch 30/60\n","\n","Epoch 30: val_loss improved from 4.67199 to 4.54839, saving model to ck3/cp.ckpt\n","51/51 - 60s - loss: 2.8442 - accuracy: 1.0000 - val_loss: 4.5484 - val_accuracy: 0.6298 - 60s/epoch - 1s/step\n","Epoch 31/60\n","\n","Epoch 31: val_loss improved from 4.54839 to 4.43743, saving model to ck3/cp.ckpt\n","51/51 - 60s - loss: 2.7936 - accuracy: 1.0000 - val_loss: 4.4374 - val_accuracy: 0.6538 - 60s/epoch - 1s/step\n","Epoch 32/60\n","\n","Epoch 32: val_loss did not improve from 4.43743\n","51/51 - 58s - loss: 2.7424 - accuracy: 1.0000 - val_loss: 4.4582 - val_accuracy: 0.6202 - 58s/epoch - 1s/step\n","Epoch 33/60\n","\n","Epoch 33: val_loss did not improve from 4.43743\n","51/51 - 60s - loss: 2.6906 - accuracy: 1.0000 - val_loss: 4.4518 - val_accuracy: 0.6154 - 60s/epoch - 1s/step\n","Epoch 34/60\n","\n","Epoch 34: val_loss improved from 4.43743 to 4.31498, saving model to ck3/cp.ckpt\n","51/51 - 58s - loss: 2.6389 - accuracy: 1.0000 - val_loss: 4.3150 - val_accuracy: 0.6635 - 58s/epoch - 1s/step\n","Epoch 35/60\n","\n","Epoch 35: val_loss did not improve from 4.31498\n","51/51 - 60s - loss: 2.5882 - accuracy: 1.0000 - val_loss: 4.3195 - val_accuracy: 0.6442 - 60s/epoch - 1s/step\n","Epoch 36/60\n","\n","Epoch 36: val_loss improved from 4.31498 to 4.21511, saving model to ck3/cp.ckpt\n","51/51 - 60s - loss: 2.5411 - accuracy: 1.0000 - val_loss: 4.2151 - val_accuracy: 0.6442 - 60s/epoch - 1s/step\n","Epoch 37/60\n","\n","Epoch 37: val_loss did not improve from 4.21511\n","51/51 - 60s - loss: 2.4988 - accuracy: 1.0000 - val_loss: 4.3622 - val_accuracy: 0.5962 - 60s/epoch - 1s/step\n","Epoch 38/60\n","\n","Epoch 38: val_loss did not improve from 4.21511\n","51/51 - 60s - loss: 2.4561 - accuracy: 1.0000 - val_loss: 4.2892 - val_accuracy: 0.6058 - 60s/epoch - 1s/step\n","Epoch 39/60\n","\n","Epoch 39: val_loss did not improve from 4.21511\n","51/51 - 58s - loss: 2.4120 - accuracy: 1.0000 - val_loss: 4.2659 - val_accuracy: 0.6058 - 58s/epoch - 1s/step\n","Epoch 40/60\n","\n","Epoch 40: val_loss did not improve from 4.21511\n","51/51 - 60s - loss: 2.3672 - accuracy: 1.0000 - val_loss: 4.3183 - val_accuracy: 0.5865 - 60s/epoch - 1s/step\n","Epoch 41/60\n","\n","Epoch 41: val_loss improved from 4.21511 to 4.10885, saving model to ck3/cp.ckpt\n","51/51 - 60s - loss: 2.3229 - accuracy: 1.0000 - val_loss: 4.1089 - val_accuracy: 0.6154 - 60s/epoch - 1s/step\n","Epoch 42/60\n","\n","Epoch 42: val_loss did not improve from 4.10885\n","51/51 - 58s - loss: 2.2791 - accuracy: 1.0000 - val_loss: 4.1227 - val_accuracy: 0.6058 - 58s/epoch - 1s/step\n","Epoch 43/60\n","\n","Epoch 43: val_loss improved from 4.10885 to 4.04698, saving model to ck3/cp.ckpt\n","51/51 - 58s - loss: 2.2359 - accuracy: 1.0000 - val_loss: 4.0470 - val_accuracy: 0.6154 - 58s/epoch - 1s/step\n","Epoch 44/60\n","\n","Epoch 44: val_loss improved from 4.04698 to 3.97347, saving model to ck3/cp.ckpt\n","51/51 - 60s - loss: 2.1933 - accuracy: 1.0000 - val_loss: 3.9735 - val_accuracy: 0.6346 - 60s/epoch - 1s/step\n","Epoch 45/60\n","\n","Epoch 45: val_loss improved from 3.97347 to 3.93859, saving model to ck3/cp.ckpt\n","51/51 - 60s - loss: 2.1511 - accuracy: 1.0000 - val_loss: 3.9386 - val_accuracy: 0.6298 - 60s/epoch - 1s/step\n","Epoch 46/60\n","\n","Epoch 46: val_loss did not improve from 3.93859\n","51/51 - 59s - loss: 2.1094 - accuracy: 1.0000 - val_loss: 4.0287 - val_accuracy: 0.6154 - 59s/epoch - 1s/step\n","Epoch 47/60\n","\n","Epoch 47: val_loss improved from 3.93859 to 3.87169, saving model to ck3/cp.ckpt\n","51/51 - 58s - loss: 2.0685 - accuracy: 1.0000 - val_loss: 3.8717 - val_accuracy: 0.6298 - 58s/epoch - 1s/step\n","Epoch 48/60\n","\n","Epoch 48: val_loss improved from 3.87169 to 3.79667, saving model to ck3/cp.ckpt\n","51/51 - 60s - loss: 2.0284 - accuracy: 1.0000 - val_loss: 3.7967 - val_accuracy: 0.6298 - 60s/epoch - 1s/step\n","Epoch 49/60\n","\n","Epoch 49: val_loss improved from 3.79667 to 3.71790, saving model to ck3/cp.ckpt\n","51/51 - 60s - loss: 1.9890 - accuracy: 1.0000 - val_loss: 3.7179 - val_accuracy: 0.6587 - 60s/epoch - 1s/step\n","Epoch 50/60\n","\n","Epoch 50: val_loss improved from 3.71790 to 3.66173, saving model to ck3/cp.ckpt\n","51/51 - 60s - loss: 1.9502 - accuracy: 1.0000 - val_loss: 3.6617 - val_accuracy: 0.6298 - 60s/epoch - 1s/step\n","Epoch 51/60\n","\n","Epoch 51: val_loss did not improve from 3.66173\n","51/51 - 58s - loss: 1.9119 - accuracy: 1.0000 - val_loss: 3.7219 - val_accuracy: 0.6250 - 58s/epoch - 1s/step\n","Epoch 52/60\n","\n","Epoch 52: val_loss did not improve from 3.66173\n","51/51 - 60s - loss: 1.8743 - accuracy: 1.0000 - val_loss: 3.6906 - val_accuracy: 0.6250 - 60s/epoch - 1s/step\n","Epoch 53/60\n","\n","Epoch 53: val_loss did not improve from 3.66173\n","51/51 - 60s - loss: 1.8374 - accuracy: 1.0000 - val_loss: 3.7620 - val_accuracy: 0.6106 - 60s/epoch - 1s/step\n","Epoch 54/60\n","\n","Epoch 54: val_loss improved from 3.66173 to 3.57347, saving model to ck3/cp.ckpt\n","51/51 - 60s - loss: 1.8013 - accuracy: 1.0000 - val_loss: 3.5735 - val_accuracy: 0.6394 - 60s/epoch - 1s/step\n","Epoch 55/60\n","\n","Epoch 55: val_loss did not improve from 3.57347\n","51/51 - 60s - loss: 1.7660 - accuracy: 1.0000 - val_loss: 3.5934 - val_accuracy: 0.6202 - 60s/epoch - 1s/step\n","Epoch 56/60\n","\n","Epoch 56: val_loss improved from 3.57347 to 3.45622, saving model to ck3/cp.ckpt\n","51/51 - 60s - loss: 1.7331 - accuracy: 1.0000 - val_loss: 3.4562 - val_accuracy: 0.6298 - 60s/epoch - 1s/step\n","Epoch 57/60\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-142-dc85e296cb4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m              ]\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0md_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnobbr_train_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnobbr_train_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnobbr_valid_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnobbr_valid_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1639\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1640\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1641\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1642\u001b[0m                         with tf.profiler.experimental.Trace(\n\u001b[1;32m   1643\u001b[0m                             \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36msteps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1369\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m             \u001b[0moriginal_spe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1372\u001b[0m             can_run_full_execution = (\n\u001b[1;32m   1373\u001b[0m                 \u001b[0moriginal_spe\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    637\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m     raise NotImplementedError(\n\u001b[1;32m    641\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \"\"\"\n\u001b[1;32m   1154\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1155\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1156\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1119\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["## Evaluation"],"metadata":{"id":"caK6A26I48kw"}},{"cell_type":"code","source":["d_model.evaluate(test_x,test_labels,verbose=2)"],"metadata":{"id":"gJ-4p5sDgDhr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677905081476,"user_tz":-540,"elapsed":3378,"user":{"displayName":"­권오민 / 학생 / 전기·정보공학부","userId":"14836171550716712824"}},"outputId":"e6590525-8761-4b7a-a66f-f49128e39f32"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["7/7 - 3s - loss: 3.0348 - accuracy: 0.7222 - 3s/epoch - 403ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["[3.0348150730133057, 0.7222222089767456]"]},"metadata":{},"execution_count":145}]},{"cell_type":"code","source":["d_model.evaluate(valid_x,valid_labels,verbose=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j6jjnrndXu7y","executionInfo":{"status":"ok","timestamp":1677895630438,"user_tz":-540,"elapsed":21697,"user":{"displayName":"­권오민 / 학생 / 전기·정보공학부","userId":"14836171550716712824"}},"outputId":"13ff3441-4fbc-4aa7-cca3-d7a67fdab6c4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["23/23 - 11s - loss: 6.6782 - accuracy: 0.5803 - 11s/epoch - 462ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["[6.678152084350586, 0.5803323984146118]"]},"metadata":{},"execution_count":31}]},{"cell_type":"markdown","source":["##Grad Cam"],"metadata":{"id":"fGrlRbPYOfN6"}},{"cell_type":"code","source":["d_model.summary()"],"metadata":{"id":"QvlwU_LmI4Xl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677911807839,"user_tz":-540,"elapsed":413,"user":{"displayName":"­권오민 / 학생 / 전기·정보공학부","userId":"14836171550716712824"}},"outputId":"0b58f400-8ce6-41fe-e7da-ed4b89c55771"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_4\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 171, 300, 1)]     0         \n","                                                                 \n"," conv2d (Conv2D)             (None, 171, 150, 256)     1024      \n","                                                                 \n"," batch_normalization (BatchN  (None, 171, 150, 256)    1024      \n"," ormalization)                                                   \n","                                                                 \n"," re_lu (ReLU)                (None, 171, 150, 256)     0         \n","                                                                 \n"," model (Functional)          (None, 171, 75, 256)      791552    \n","                                                                 \n"," model_1 (Functional)        (None, 171, 38, 256)      791552    \n","                                                                 \n"," model_2 (Functional)        (None, 171, 19, 256)      791552    \n","                                                                 \n"," model_3 (Functional)        (None, 171, 10, 256)      791552    \n","                                                                 \n"," flatten (Flatten)           (None, 437760)            0         \n","                                                                 \n"," dropout_4 (Dropout)         (None, 437760)            0         \n","                                                                 \n"," dense (Dense)               (None, 7)                 3064327   \n","                                                                 \n"," softmax (Softmax)           (None, 7)                 0         \n","                                                                 \n"," reshape (Reshape)           (None, 1, 1, 7)           0         \n","                                                                 \n","=================================================================\n","Total params: 6,232,583\n","Trainable params: 6,223,879\n","Non-trainable params: 8,704\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"PXgsKxfaV5mm"}},{"cell_type":"code","source":["#사전 학습된 신경망 모델을 불러오고 구조 확인\n","    #지정된 영상을 불러와 크기 조정하고 화면에 디스플레이\n","test_x = np.load(\"test_x.npy\")\n","\n","index = np.random.randint(len(test_x))\n","print(index)\n","test_gradcam = test_x[int(index)]\n","print(test_gradcam.shape)\n","\n","plt.imshow(test_gradcam)\n","plt.show()\n","test_gradcam = test_gradcam.reshape((171, 300, 1))\n","#영상을 신경망 형태로 변환\n","x=test_gradcam\n","x=np.expand_dims(x,axis=0)\n","\n","#인식을 시도하고 top-5결과를 출력\n","preds = d_model.predict(x)\n","#신경망 모델의 특 징  추출 부분에서 마지막 층을 지정\n","#특징 추출 부분만으로 구성된 model_1만들기\n","\n","input1 = keras.Input(shape=(171,300,1))\n","last_conv_layer = model.get_layer(\"conv2d\")(input1)\n","last_conv_layer = model.get_layer(\"batch_normalization\")(last_conv_layer)\n","last_conv_layer = model.get_layer(\"re_lu\")(last_conv_layer)\n","last_conv_layer = model.get_layer(\"model\")(last_conv_layer)\n","last_conv_layer = model.get_layer(\"model_1\")(last_conv_layer)\n","last_conv_layer = model.get_layer(\"model_2\")(last_conv_layer)\n","last_conv_layer = model.get_layer(\"model_3\")(last_conv_layer)\n","\n","model_1 = keras.Model(input1, last_conv_layer)\n","print(model_1.summary())\n","print(x.shape)\n","#분류 (전역평균풀링 또는 완전연결층) 부분만으로 구성된 model__2만들기\n","input_2 = keras.Input(shape=model_1.output.shape[1:])\n","print(input_2.shape)\n","x_2 = model.get_layer(\"flatten\")(input_2)\n","x_2 = model.get_layer(\"dense\")(x_2)\n","x_2 = model.get_layer(\"softmax\")(x_2)\n","x_2 = model.get_layer(\"reshape\")(x_2)\n","model_2 =keras.Model(input_2,x_2)\n","print(model_2.summary())\n","#GradientTape함수를 이용한 그레디언트 계산\n","with tf.GradientTape() as tape:\n","output_1 = model_1(x)\n","print(output_1.shape)\n","tape.watch(output_1) #마지막 층으로 미분하기 위한 준비\n","preds = model_2(output_1)\n","print(preds.shape)\n","class_id = tf.argmax(preds[0,0,0,:])\n","print(class_id)\n","output_2 = preds[:,:,:,class_id]\n","\n","grads = tape.gradient(output_2, output_1) #그레디언트 계산\n","pooled_grads = tf.reduce_mean(grads,axis=(0,1,2)) #식5 적용\n","\n","output_1 = output_1.numpy()[0]\n","pooled_grads = pooled_grads.numpy()\n","for i in range(pooled_grads.shape[-1]):\n","    output_1[:,:,i]*=pooled_grads[i]\n","heatmap=np.mean(output_1, axis=-1)\n","\n","heatmap =np.maximum(heatmap, 0)/np.max(heatmap) #정규화\n","plt.matshow(heatmap)\n","\n","#열지도를 입력 영상에 씌움\n","img=test_gradcam\n","heatmap=np.uint8(255*heatmap) # [0,255]로 변환\n","\n","jet = cm.get_cmap(\"jet\") #jet 컬러맵으로 표시\n","color = jet(np.arange(256))[:,:3]\n","color_heatmap = color[heatmap]\n","\n","color_heatmap = keras.preprocessing.image.array_to_img(color_heatmap)\n","color_heatmap = color_heatmap.resize((img.shape[1], img.shape[0]))\n","color_heatmap = keras.preprocessing.image.img_to_array(color_heatmap)\n","\n","overlay_img= color_heatmap*0.4+img #덧씌움\n","overlay_img = keras.preprocessing.image.array_to_img(overlay_img)\n","plt.matshow(overlay_img)\n","plt.show()"],"metadata":{"id":"zv913eqmOWHc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["index = np.random.randint(len(test_x))\n","print(index)\n","test_gradcam = test_x[int(index)].reshape((-1,171,300,1))"],"metadata":{"id":"rpvyU115OYsB"},"execution_count":null,"outputs":[]}]}